{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anohl\\OneDrive\\Dokumente\\A_Uni_stuff\\Albstadt\\Semester 2\\Computer_vision\\Aufgaben\\cv_class_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "from transformers import AutoModelForObjectDetection, TrainingArguments, Trainer, YolosImageProcessor\n",
    "from PIL import Image, ImageDraw\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import time\n",
    "import configparser\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.ini\")\n",
    "# AUTH_TOKEN = config[\"auth\"][\"token\"]\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "IMAGE_PROCESSOR_GLOBAL = YolosImageProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation/Test-Split abgeschlossen! Daten in 'c:\\Users\\anohl\\OneDrive\\Dokumente\\A_Uni_stuff\\Albstadt\\Semester 2\\Computer_vision\\Aufgaben\\Data\\Kugellager_Data\\YOLO_data' gespeichert.\n",
      "Train: 480 | Test: 120\n"
     ]
    }
   ],
   "source": [
    "def clear_directory(directory):\n",
    "    \"\"\"\n",
    "    Löscht den gesamten Inhalt eines Verzeichnisses, ohne das Verzeichnis selbst zu entfernen.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Pfad zum Verzeichnis.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory):\n",
    "        for item in os.listdir(directory):\n",
    "            item_path = os.path.join(directory, item)\n",
    "            if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "                os.unlink(item_path)  \n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)  \n",
    "\n",
    "\n",
    "def split_dataset(images_dir, labels_dir, output_dir, test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    Teilt einen Datensatz (Bilder + Labels) in Training, Validierung und Test auf.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Pfad zum Ordner mit den Bildern.\n",
    "        labels_dir (str): Pfad zum Ordner mit den Labels.\n",
    "        output_dir (str): Pfad zum Ordner, in dem die aufgeteilten Daten gespeichert werden sollen.\n",
    "        val_ratio (float): Verhältnis der Validierungsdaten (zwischen 0 und 1). Standard: 0.1.\n",
    "        test_ratio (float): Verhältnis der Testdaten (zwischen 0 und 1). Standard: 0.1.\n",
    "        seed (int): Zufallssaat für Reproduzierbarkeit. Standard: 42.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Unterordner-Pfade\n",
    "    train_images_dir = os.path.join(output_dir, \"train/images\")\n",
    "    train_labels_dir = os.path.join(output_dir, \"train/labels\")\n",
    "    test_images_dir = os.path.join(output_dir, \"test/images\")\n",
    "    test_labels_dir = os.path.join(output_dir, \"test/labels\")\n",
    "    \n",
    "    # Ordner neu erstellen\n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    os.makedirs(test_images_dir, exist_ok=True)\n",
    "    os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "    for subdir in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\n",
    "        clear_directory(subdir)\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "\n",
    "    # Liste aller Bilder\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    # Shuffle und Split\n",
    "    random.seed(seed)\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    test_split = int(len(image_files) * test_ratio)\n",
    "    \n",
    "    test_files = image_files[:test_split]\n",
    "    train_files = image_files[test_split:]\n",
    "\n",
    "    # Dateien kopieren\n",
    "    def copy_files(file_list, dest_images_dir, dest_labels_dir):\n",
    "        for file in file_list:\n",
    "            shutil.copy(os.path.join(images_dir, file), os.path.join(dest_images_dir, file))\n",
    "            label_file = file.rsplit('.', 1)[0] + '.txt'\n",
    "            if os.path.exists(os.path.join(labels_dir, label_file)):\n",
    "                shutil.copy(os.path.join(labels_dir, label_file), os.path.join(dest_labels_dir, label_file))\n",
    "\n",
    "    copy_files(train_files, train_images_dir, train_labels_dir)\n",
    "    copy_files(test_files, test_images_dir, test_labels_dir)\n",
    "\n",
    "    print(f\"Train/Validation/Test-Split abgeschlossen! Daten in '{output_dir}' gespeichert.\")\n",
    "    print(f\"Train: {len(train_files)} | Test: {len(test_files)}\")\n",
    "\n",
    "yolo_images_dir = os.path.join(BASE_DIR, \"Data\", \"Kugellager_Data\", \"YOLO_data\", \"yolo_images_dump\")\n",
    "yolo_labels_dir = os.path.join(BASE_DIR, \"Data\", \"Kugellager_Data\", \"YOLO_data\", \"yolo_labels_dump\")\n",
    "yolo_output_dir = os.path.join(BASE_DIR, \"Data\", \"Kugellager_Data\", \"YOLO_data\")\n",
    "\n",
    "split_dataset(images_dir=yolo_images_dir,\n",
    "              labels_dir=yolo_labels_dir,\n",
    "              output_dir=yolo_output_dir,\n",
    "              test_ratio=0.2,\n",
    "              seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_yolo_to_custom_format(images_dir, labels_dir, categories):\n",
    "    \"\"\"\n",
    "    Converts YOLO annotations to a custom dataset format similar to CPPE-5.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Path to the images directory.\n",
    "        labels_dir (str): Path to the YOLO labels directory.\n",
    "        categories (list): List of category names.\n",
    "\n",
    "    Returns:\n",
    "        list: A dataset where each entry contains image metadata and associated objects.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    annotation_id = 0\n",
    "    image_id = 0\n",
    "\n",
    "    for image_file in sorted(os.listdir(images_dir)):\n",
    "        if not image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "\n",
    "        # Open the image as a PIL image object\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "            # Prepare the image entry\n",
    "            image_entry = {\n",
    "                'image_id': image_id,\n",
    "                'image': img.copy(),  # Keep a reference to the PIL image\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'objects': {\n",
    "                    'id': [],\n",
    "                    'area': [],\n",
    "                    'bbox': [],\n",
    "                    'category': []\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Corresponding label file in YOLO format\n",
    "            label_file = os.path.join(labels_dir, image_file.rsplit('.', 1)[0] + '.txt')\n",
    "            if os.path.exists(label_file):\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        category_id = int(parts[0])\n",
    "                        x_center, y_center, box_width, box_height = map(float, parts[1:])\n",
    "\n",
    "                        # Convert YOLO to bounding box coordinates\n",
    "                        x_min = (x_center - box_width / 2) * width\n",
    "                        y_min = (y_center - box_height / 2) * height\n",
    "                        bbox_width = box_width * width\n",
    "                        bbox_height = box_height * height\n",
    "                        area = bbox_width * bbox_height\n",
    "\n",
    "                        # Append object data\n",
    "                        image_entry['objects']['id'].append(annotation_id)\n",
    "                        image_entry['objects']['area'].append(int(area))\n",
    "                        image_entry['objects']['bbox'].append([\n",
    "                            round(x_min, 1),\n",
    "                            round(y_min, 1),\n",
    "                            round(bbox_width, 1),\n",
    "                            round(bbox_height, 1)\n",
    "                        ])\n",
    "                        image_entry['objects']['category'].append(category_id)\n",
    "\n",
    "                        annotation_id += 1\n",
    "\n",
    "            dataset.append(image_entry)\n",
    "            image_id += 1\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "categories_kugellager = [\n",
    "    {\"id\": 0, \"name\": \"defect\"},\n",
    "]\n",
    "images_dir_kugellager_train = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/train/images\")\n",
    "labels_dir_kugellager_train = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/train/labels\")\n",
    "\n",
    "dataset_kugellager_train = Dataset.from_list(convert_yolo_to_custom_format(images_dir_kugellager_train, labels_dir_kugellager_train, categories_kugellager))\n",
    "\n",
    "images_dir_kugellager_test = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/test/images\")\n",
    "labels_dir_kugellager_test = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/test/labels\")\n",
    "\n",
    "dataset_kugellager_test = Dataset.from_list(convert_yolo_to_custom_format(images_dir_kugellager_test, labels_dir_kugellager_test, categories_kugellager))\n",
    "\n",
    "\n",
    "\n",
    "images_dir_kugellager_train_halb = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/train_halb/images\")\n",
    "labels_dir_kugellager_train_halb = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/train_halb/labels\")\n",
    "\n",
    "dataset_kugellager_train_halb = Dataset.from_list(convert_yolo_to_custom_format(images_dir_kugellager_train_halb, labels_dir_kugellager_train_halb, categories_kugellager))\n",
    "\n",
    "images_dir_kugellager_test_halb = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/test_halb/images\")\n",
    "labels_dir_kugellager_test_halb = os.path.join(BASE_DIR, \"Data/Kugellager_Data/YOLO_Data/test_halb/labels\")\n",
    "\n",
    "dataset_kugellager_test_halb = Dataset.from_list(convert_yolo_to_custom_format(images_dir_kugellager_test_halb, labels_dir_kugellager_test_halb, categories_kugellager))\n",
    "\n",
    "categories_oberfläche = [\n",
    "    {\"id\": 0, \"name\": \"crazing\"},\n",
    "    {\"id\": 1, \"name\": \"inclusion\"},\n",
    "    {\"id\": 2, \"name\": \"patches\"},\n",
    "    {\"id\": 3, \"name\": \"pitted surface\"},\n",
    "    {\"id\": 4, \"name\": \"rolled in scale\"},\n",
    "    {\"id\": 5, \"name\": \"scratches\"}\n",
    "]\n",
    "\n",
    "images_dir_oberfläche_train = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/train/images\")\n",
    "labels_dir_oberfläche_train = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/train/labels\")\n",
    "\n",
    "dataset_oberfläche_train = Dataset.from_list(convert_yolo_to_custom_format(images_dir_oberfläche_train, labels_dir_oberfläche_train, categories_oberfläche))\n",
    "\n",
    "images_dir_oberfläche_test = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/test/images\")\n",
    "labels_dir_oberfläche_test = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/test/labels\")\n",
    "\n",
    "dataset_oberfläche_test = Dataset.from_list(convert_yolo_to_custom_format(images_dir_oberfläche_test, labels_dir_oberfläche_test, categories_oberfläche))\n",
    "\n",
    "\n",
    "\n",
    "images_dir_oberfläche_train_halb = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/train_halb/images\")\n",
    "labels_dir_oberfläche_train_halb = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/train_halb/labels\")\n",
    "\n",
    "dataset_oberfläche_train_halb = Dataset.from_list(convert_yolo_to_custom_format(images_dir_oberfläche_train_halb, labels_dir_oberfläche_train_halb, categories_oberfläche))\n",
    "\n",
    "images_dir_oberfläche_test_halb = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/test_halb/images\")\n",
    "labels_dir_oberfläche_test_halb = os.path.join(BASE_DIR, \"Data/Oberflächen_Data/YOLO_Data/test_halb/labels\")\n",
    "\n",
    "dataset_oberfläche_test_halb = Dataset.from_list(convert_yolo_to_custom_format(images_dir_oberfläche_test_halb, labels_dir_oberfläche_test_halb, categories_oberfläche))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das hier war lediglich Code um ein memory Problem zu lösen, das beim Training auftrat\n",
    "\n",
    "# print(\"CUDA available:\", torch.cuda.is_available())\n",
    "# print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "# print(\"CUDA version:\", torch.version.cuda)\n",
    "# print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "# total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "\n",
    "# # Belegter Speicher (in Bytes)\n",
    "# allocated_memory = torch.cuda.memory_allocated(0)\n",
    "\n",
    "# # Zwischengespeicherter Speicher\n",
    "# cached_memory = torch.cuda.memory_reserved(0)\n",
    "\n",
    "# print(f\"Gesamtspeicher: {total_memory / 1e9:.2f} GB\")\n",
    "# print(f\"Belegter Speicher: {allocated_memory / 1e9:.2f} GB\")\n",
    "# print(f\"Zwischengespeicherter Speicher: {cached_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_anns(image_id, category, area, bbox):\n",
    "    annotations = []\n",
    "    for i in range(0, len(category)):\n",
    "\n",
    "        new_ann = {\n",
    "            \"id\": image_id,\n",
    "            \"category_id\": category[i],  # Hier wird das richtige category ID verwendet\n",
    "            \"isCrowd\": 0,\n",
    "            \"area\": area[i],\n",
    "            \"bbox\": list(bbox[i]),\n",
    "        }\n",
    "\n",
    "        annotations.append(new_ann)\n",
    "    return annotations\n",
    "\n",
    "# Create annotations such that they match the expected form by the algorithm\n",
    "def transform_ann(examples, image_processor = YolosImageProcessor()):\n",
    "    image_ids = examples[\"image_id\"]\n",
    "    images, bboxes, area, categories = [], [], [], []\n",
    "    for image, objects in zip(examples[\"image\"], examples[\"objects\"]): \n",
    "        image = np.array(image.convert(\"RGB\"))[:, :, ::-1]\n",
    "        area.append(objects[\"area\"])\n",
    "        images.append(image)\n",
    "        bboxes.append(objects[\"bbox\"])\n",
    "        categories.append(objects[\"category\"])\n",
    "\n",
    "    targets = [\n",
    "    {\"image_id\": id_, \"annotations\": formatted_anns(id_, cat_, ar_, box_)}\n",
    "    for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)\n",
    "    ]\n",
    "\n",
    "    return image_processor(images=images, annotations=targets, return_tensors=\"pt\") # Is applied on the whole batch\n",
    "\n",
    "def collate_fn(batch, image_processor = YolosImageProcessor()):\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    #batch[\"pixel_mask\"] = encoding[\"pixel_mask\"] # For object detection we do not need this - only needed for segmentation.\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch\n",
    "\n",
    "\n",
    "def model_training(categories, model_name, train_data, validation_data, num_epochs=3, image_processor=YolosImageProcessor(), output_name=\"Kugellager\"):\n",
    "    # Mapping zwischen IDs und Labels\n",
    "    id2label = {category['id']: category['name'] for category in categories}\n",
    "    label2id = {category['name']: category['id'] for category in categories} \n",
    "\n",
    "    # Modell initialisieren\n",
    "    model = AutoModelForObjectDetection.from_pretrained(\n",
    "        model_name,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        ignore_mismatched_sizes=True,  \n",
    "    )\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\") \n",
    "\n",
    "    if device == \"cpu\":\n",
    "        training_args = TrainingArguments(\n",
    "        output_dir=f\"trained_model/{output_name}/{model_name}\", \n",
    "        remove_unused_columns=False, \n",
    "        load_best_model_at_end=False, \n",
    "        save_strategy=\"no\", \n",
    "        eval_strategy=\"epoch\", \n",
    "        per_device_train_batch_size=2, \n",
    "        push_to_hub=False,\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=num_epochs\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        training_args = TrainingArguments(\n",
    "        output_dir=f\"trained_model/{output_name}/{model_name}\", \n",
    "        remove_unused_columns=False, \n",
    "        load_best_model_at_end=False, \n",
    "        save_strategy=\"no\", \n",
    "        eval_strategy=\"epoch\", \n",
    "        per_device_train_batch_size=10, \n",
    "        push_to_hub=False,\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=num_epochs\n",
    "        )\n",
    "\n",
    "    # Hier wird dafür gesorgt, dass das Modell auch auf der Grafikkarte trainert werden kann, wenn eine vorhanden sein sollte. \n",
    "    model.to(device)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=collate_fn, \n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=validation_data,\n",
    "        tokenizer=image_processor,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    evaluation_results = trainer.evaluate()\n",
    "\n",
    "    # Plotten der Losses aus dem TrainerState\n",
    "    train_logs = trainer.state.log_history\n",
    "\n",
    "    # Extrahiere Training und Evaluation Losses\n",
    "    train_losses = [log['loss'] for log in train_logs if 'loss' in log]\n",
    "    eval_losses = [log['eval_loss'] for log in train_logs if 'eval_loss' in log]\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    \n",
    "    if len(eval_losses) > 0:\n",
    "        # Falls unterschiedliche Längen, interpoliere oder schneide\n",
    "        if len(eval_losses) != len(train_losses):\n",
    "            # Interpoliere eval_losses auf die Länge von train_losses\n",
    "            x_train = np.linspace(0, len(train_losses)-1, len(train_losses))\n",
    "            x_eval = np.linspace(0, len(train_losses)-1, len(eval_losses))\n",
    "            eval_losses_interpolated = np.interp(x_train, x_eval, eval_losses)\n",
    "            \n",
    "            plt.plot(eval_losses_interpolated, label='Evaluation Loss', color='red')\n",
    "        else:\n",
    "            plt.plot(eval_losses, label='Evaluation Loss', color='red')\n",
    "\n",
    "    plt.title(f'Loss Progression for {model_name}')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"trained_model/{output_name}/{model_name}/loss_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "    save_path = f\"trained_model/{output_name}/{model_name}/final_model\"\n",
    "    model.save_pretrained(save_path)\n",
    "\n",
    "    return evaluation_results, train_losses, eval_losses\n",
    "    \n",
    "\n",
    "# Transform data such that it can be feed to the model\n",
    "train_data_kugellager = dataset_kugellager_train.with_transform(transform_ann)\n",
    "test_data_kugellager = dataset_kugellager_test.with_transform(transform_ann)\n",
    "\n",
    "train_data_oberfläche = dataset_oberfläche_train.with_transform(transform_ann)\n",
    "test_data_oberfläche = dataset_oberfläche_test.with_transform(transform_ann)\n",
    "\n",
    "\n",
    "train_data_kugellager_halb = dataset_kugellager_train_halb.with_transform(transform_ann)\n",
    "test_data_kugellager_halb = dataset_kugellager_test_halb.with_transform(transform_ann)\n",
    "\n",
    "train_data_oberfläche_halb = dataset_oberfläche_train_halb.with_transform(transform_ann)\n",
    "test_data_oberfläche_halb = dataset_oberfläche_test_halb.with_transform(transform_ann)\n",
    "\n",
    "best_models_kugellager_dict = {}\n",
    "best_models_oberfläche_dict = {}\n",
    "\n",
    "best_models_kugellager_dict_halb = {}\n",
    "best_models_oberfläche_dict_halb = {}\n",
    "\n",
    "# \"ultralytics/yolov11-m\", \n",
    "# \"jparedesDS/welding-defects-detection\",\n",
    "# \"facebook/detr-resnet-50\", \n",
    "# \"hustvl/yolos-small\",\n",
    "# \"hustvl/yolos-tiny\"\n",
    "# \"jparedesDS/welding-defects-detection\",\n",
    "# \"hustvl/yolos-small\",\n",
    "# \"hustvl/yolos-tiny\",\n",
    "model_training_list = [ \"facebook/detr-resnet-50\", ]\n",
    "\n",
    "# for model_name in model_training_list:\n",
    "#     evaluation_results, train_losses, eval_losses = model_training(\n",
    "#         categories=categories_kugellager, \n",
    "#         model_name=model_name, \n",
    "#         train_data=train_data_kugellager, \n",
    "#         validation_data=test_data_kugellager, \n",
    "#         num_epochs=30,\n",
    "#         output_name=\"Kugellager\"\n",
    "#     )\n",
    "#     best_models_kugellager_dict[model_name] = {\n",
    "#         'evaluation_results': evaluation_results,\n",
    "#         'train_losses': train_losses,\n",
    "#         'eval_losses': eval_losses\n",
    "#     }\n",
    "\n",
    "\n",
    "# for model_name in model_training_list:\n",
    "#     evaluation_results, train_losses, eval_losses = model_training(\n",
    "#         categories=categories_oberfläche, \n",
    "#         model_name=model_name, \n",
    "#         train_data=train_data_oberfläche, \n",
    "#         validation_data=test_data_oberfläche, \n",
    "#         num_epochs=30,\n",
    "#         output_name=\"Oberfläche\"\n",
    "#     )\n",
    "#     best_models_oberfläche_dict[model_name] = {\n",
    "#         'evaluation_results': evaluation_results,\n",
    "#         'train_losses': train_losses,\n",
    "#         'eval_losses': eval_losses\n",
    "#     }\n",
    "\n",
    "\n",
    "# for model_name in model_training_list:\n",
    "#     evaluation_results, train_losses, eval_losses = model_training(\n",
    "#         categories=categories_kugellager, \n",
    "#         model_name=model_name, \n",
    "#         train_data=train_data_kugellager_halb, \n",
    "#         validation_data=test_data_kugellager_halb, \n",
    "#         num_epochs=30,\n",
    "#         output_name=\"Kugellager_halb\"\n",
    "#     )\n",
    "#     best_models_kugellager_dict_halb[model_name] = {\n",
    "#         'evaluation_results': evaluation_results,\n",
    "#         'train_losses': train_losses,\n",
    "#         'eval_losses': eval_losses\n",
    "#     }\n",
    "\n",
    "\n",
    "# for model_name in model_training_list:\n",
    "#     evaluation_results, train_losses, eval_losses = model_training(\n",
    "#         categories=categories_oberfläche, \n",
    "#         model_name=model_name, \n",
    "#         train_data=train_data_oberfläche_halb, \n",
    "#         validation_data=test_data_oberfläche_halb, \n",
    "#         num_epochs=30,\n",
    "#         output_name=\"Oberfläche_halb\"\n",
    "#     )\n",
    "#     best_models_oberfläche_dict_halb[model_name] = {\n",
    "#         'evaluation_results': evaluation_results,\n",
    "#         'train_losses': train_losses,\n",
    "#         'eval_losses': eval_losses\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(img, results, output_dir=None):\n",
    "    if isinstance(img, str):\n",
    "        image = Image.open(img)\n",
    "    else:\n",
    "        image = img\n",
    "    image = image.copy()\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    for obj in results:\n",
    "        box = obj[\"box\"]\n",
    "        x = int(box[\"xmin\"])\n",
    "        y = int(box[\"ymin\"])\n",
    "        x2 = int(box[\"xmax\"])\n",
    "        y2 = int(box[\"ymax\"])\n",
    "        \n",
    "        draw.rectangle([(x, y), (x2, y2)], outline=\"orange\", width=2)\n",
    "        \n",
    "        label_text = f\"{obj['label']} - {np.round(obj['score'], 3)}\"\n",
    "        draw.text((x, y - 20), label_text, fill=\"orange\", stroke_width=2, stroke_fill=\"white\")\n",
    "    \n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"detection_result_{np.random.randint(10e6)}.jpg\")\n",
    "        image.save(output_path)\n",
    "        return output_path\n",
    "    return np.array(image) \n",
    "\n",
    "def load_model_for_inference(model_path, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"Load the trained model and move it to the specified device\"\"\"\n",
    "    model = AutoModelForObjectDetection.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_predictions(model, image, image_processor=YolosImageProcessor(), confidence_threshold=0.5):\n",
    "    \"\"\"Process an image and return predictions with timing information\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    # Preprocessing timing\n",
    "    preprocess_start = time.time()\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    preprocess_time = time.time() - preprocess_start\n",
    "    \n",
    "    # Inference timing\n",
    "    inference_start = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    inference_time = time.time() - inference_start\n",
    "    \n",
    "    # Post-processing timing\n",
    "    postprocess_start = time.time()\n",
    "    results = []\n",
    "    \n",
    "    target_size = image_processor.post_process_object_detection(\n",
    "        outputs, \n",
    "        target_sizes=[(image.size[1], image.size[0])],\n",
    "        threshold=confidence_threshold\n",
    "    )[0]\n",
    "    \n",
    "    for score, label, box in zip(\n",
    "        target_size[\"scores\"].tolist(),\n",
    "        target_size[\"labels\"].tolist(),\n",
    "        target_size[\"boxes\"].tolist()\n",
    "    ):\n",
    "        if score >= confidence_threshold:\n",
    "            results.append({\n",
    "                \"score\": score,\n",
    "                \"label\": model.config.id2label[label],\n",
    "                \"box\": {\n",
    "                    \"xmin\": box[0],\n",
    "                    \"ymin\": box[1],\n",
    "                    \"xmax\": box[2],\n",
    "                    \"ymax\": box[3]\n",
    "                }\n",
    "            })\n",
    "    postprocess_time = time.time() - postprocess_start\n",
    "    \n",
    "    # Total time\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    timing_info = {\n",
    "        \"preprocess_time\": preprocess_time,\n",
    "        \"inference_time\": inference_time,\n",
    "        \"postprocess_time\": postprocess_time,\n",
    "        \"total_time\": total_time\n",
    "    }\n",
    "    \n",
    "    return results, timing_info\n",
    "\n",
    "def detect_and_visualize(model_path, image_path, output_dir, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Führt die nötigen Funktionen aus um ein paar test-Bilder zu lablen un gibt Informaitonen über das Timing aus.\n",
    "    \"\"\"\n",
    "    model = load_model_for_inference(model_path)\n",
    "    predictions, timing_info = get_predictions(model, image_path, confidence_threshold=confidence_threshold)\n",
    "    output_path = plot_box(image_path, predictions, output_dir)\n",
    "    \n",
    "    print(f\"Processing times:\")\n",
    "    print(f\"Preprocessing: {timing_info['preprocess_time']*1000:.1f}ms\")\n",
    "    print(f\"Inference: {timing_info['inference_time']*1000:.1f}ms\")\n",
    "    print(f\"Postprocessing: {timing_info['postprocess_time']*1000:.1f}ms\")\n",
    "    print(f\"Total time: {timing_info['total_time']*1000:.1f}ms\")\n",
    "    \n",
    "    return output_path, timing_info\n",
    "\n",
    "\n",
    "def load_random_images(image_folder, num_images=10):\n",
    "    \"\"\"\n",
    "    Lädt zufällig ausgewählte Bilder aus einem Ordner.\n",
    "    \"\"\"\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "    selected_files = random.sample(image_files, min(len(image_files), num_images))\n",
    "    return [os.path.join(image_folder, f) for f in selected_files]\n",
    "\n",
    "\n",
    "# model_path_oberfläche_yolo = os.path.join(BASE_DIR, \"trained_model\", \"Oberfläche\", \"hustvl\", \"yolos-tiny\", \"final_model\")\n",
    "# model_path_oberfläche_resnet = os.path.join(BASE_DIR, \"trained_model\", \"Oberfläche\", \"facebook\", \"detr-resnet-50\", \"final_model\")\n",
    "# list_pics_oberfläche = load_random_images(images_dir_oberfläche_test)\n",
    "# for pic in list_pics_oberfläche:\n",
    "#     detect_and_visualize(model_path=model_path_oberfläche_yolo, image_path=pic, output_dir=\"test_labeling_pics_oberfläche_yolo\")\n",
    "#     detect_and_visualize(model_path=model_path_oberfläche_resnet, image_path=pic, output_dir=\"test_labeling_pics_oberfläche_resnet\", confidence_threshold=0.4)\n",
    "\n",
    "\n",
    "# model_path_kugellager_yolo = os.path.join(BASE_DIR, \"trained_model\", \"Kugellager\", \"hustlv\", \"yolos-tiny\", \"final_model\")\n",
    "model_path_kugellager_yolo = r\"C:\\Users\\anohl\\OneDrive\\Dokumente\\A_Uni_stuff\\Albstadt\\Semester 2\\Computer_vision\\Aufgaben\\trained_model\\Oberfläche\\hustvl\\yolos-tiny\\final_model\"\n",
    "# model_path_kugellager_resnet = os.path.join(BASE_DIR, \"trained_model\", \"Kugellager\", \"facebook\", \"detr-resnet-50\", \"final_model\")\n",
    "# list_pics_kugellager = load_random_images(images_dir_kugellager_test)\n",
    "# for pic in list_pics_kugellager:\n",
    "#     detect_and_visualize(model_path=model_path_kugellager_yolo, image_path=pic, output_dir=\"test_labeling_pics_kugellager_yolo\")\n",
    "#     detect_and_visualize(model_path=model_path_kugellager_resnet, image_path=pic, output_dir=\"test_labeling_pics_kugellager_resnet\", confidence_threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully!\n",
      "Opening camera...\n",
      "Camera opened successfully!\n",
      "Starting video stream. Press 'q' to quit.\n",
      "Quitting...\n",
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "def run_video_detection(model_path, camera_id=0, confidence_threshold=0.5):\n",
    "    \"\"\"Run real-time object detection on video stream\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    model = load_model_for_inference(model_path)\n",
    "    image_processor = YolosImageProcessor()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    print(\"Opening camera...\")\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open camera with ID {camera_id}\")\n",
    "    print(\"Camera opened successfully!\")\n",
    "    \n",
    "    # Create window\n",
    "    window_name = 'Object Detection'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Initialize FPS counter\n",
    "    fps_start_time = time.time()\n",
    "    fps_counter = 0\n",
    "    fps = 0\n",
    "    \n",
    "    print(\"Starting video stream. Press 'q' to quit.\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(rgb_frame)\n",
    "            \n",
    "            # Get predictions with timing\n",
    "            predictions, timing_info = get_predictions(model, pil_image, \n",
    "                                                    image_processor=image_processor,\n",
    "                                                    confidence_threshold=confidence_threshold)\n",
    "            \n",
    "            # Draw boxes\n",
    "            result_image = plot_box(pil_image, predictions)\n",
    "            \n",
    "            # Convert back to BGR for OpenCV\n",
    "            result_frame = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Calculate and display FPS\n",
    "            fps_counter += 1\n",
    "            if time.time() - fps_start_time > 1:\n",
    "                fps = fps_counter\n",
    "                fps_counter = 0\n",
    "                fps_start_time = time.time()\n",
    "            \n",
    "            # Add timing information to frame\n",
    "            cv2.putText(result_frame, f\"FPS: {fps}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            cv2.putText(result_frame, f\"Inference: {timing_info['inference_time']*1000:.1f}ms\", \n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show the frame\n",
    "            cv2.imshow(window_name, result_frame)\n",
    "            \n",
    "            # Break on 'q' press\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                print(\"Quitting...\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        print(\"Cleaning up...\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage for single image with timing\n",
    "def detect_and_visualize(model_path, image_path, output_dir, confidence_threshold=0.5):\n",
    "    model = load_model_for_inference(model_path)\n",
    "    predictions, timing_info = get_predictions(model, image_path, confidence_threshold=confidence_threshold)\n",
    "    output_path = plot_box(image_path, predictions, output_dir)\n",
    "    \n",
    "    print(f\"Processing times:\")\n",
    "    print(f\"Preprocessing: {timing_info['preprocess_time']*1000:.1f}ms\")\n",
    "    print(f\"Inference: {timing_info['inference_time']*1000:.1f}ms\")\n",
    "    print(f\"Postprocessing: {timing_info['postprocess_time']*1000:.1f}ms\")\n",
    "    print(f\"Total time: {timing_info['total_time']*1000:.1f}ms\")\n",
    "    \n",
    "    return output_path, timing_info\n",
    "\n",
    "\n",
    "\n",
    "run_video_detection(model_path_kugellager_yolo, camera_id=0, confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: facebook/detr-resnet-50, performte mit folgenden Scores:\n",
      "{'evaluation_results': {'eval_loss': 0.9217938780784607, 'eval_runtime': 6.6457, 'eval_samples_per_second': 18.057, 'eval_steps_per_second': 2.257, 'epoch': 30.0}, 'train_losses': [2.1437, 2.1104, 1.8866, 1.4919, 1.3816, 1.4724, 1.346, 1.3652, 1.29, 1.3952, 1.4707, 1.7389, 1.882, 1.7675, 2.09, 1.5142, 1.3907, 1.4731, 1.7424, 1.5529, 1.4501, 1.6311, 1.3621, 1.3207, 1.325, 1.1566, 1.2321, 1.1528, 1.1561, 1.4008, 1.3711, 1.2979, 1.2548, 1.1528, 1.4543, 1.2188, 1.1515, 1.2485, 1.2591, 1.1641, 1.3861, 1.0755, 1.163, 1.194, 1.115, 0.9685, 1.1241, 1.1063, 1.225, 1.0863, 1.116, 1.1841, 1.0292, 0.939, 1.1251, 1.1066, 1.1021, 0.9601, 0.9873, 1.1667, 1.2175, 1.2583, 1.1623, 1.0874, 1.1932, 1.1639, 1.0901, 1.1069, 1.0272, 1.0402, 1.0037, 1.0132, 0.9903, 1.0413, 0.912, 0.8118, 0.9497, 0.8802, 0.9274, 0.969, 0.9352, 0.9586, 0.9883, 0.9851, 0.9245, 0.8756, 0.971, 0.8926, 1.1114, 0.9714, 0.9641, 0.873, 0.9988, 0.9649, 0.9028, 0.8621, 1.0643, 0.8306, 1.0284, 0.8861, 0.8929, 1.0067, 0.8658, 0.8808, 1.1036, 0.8653, 0.9697, 0.8627, 0.8737, 0.8419, 0.9257, 0.8627, 0.8534, 0.7836, 0.9571, 0.8353, 0.8403, 0.8591, 0.7485, 0.8823, 0.7448, 0.9004, 0.963, 0.7984, 0.8339, 0.8263, 0.8262, 0.8119, 0.8347, 0.8683, 0.8329, 0.7714, 0.8882, 0.8019, 0.7935, 0.7645, 0.7317, 0.8823, 0.7849, 0.7479, 0.8602, 0.6869, 0.8119, 0.7663], 'eval_losses': [1.277187705039978, 1.6899189949035645, 2.23893666267395, 1.9064829349517822, 1.4268043041229248, 1.1834368705749512, 1.3977713584899902, 1.1986801624298096, 1.1508408784866333, 1.056110143661499, 1.0013294219970703, 1.240343451499939, 1.1826287508010864, 1.0626442432403564, 0.977898895740509, 0.9773236513137817, 0.9900186061859131, 1.0640472173690796, 0.9862998723983765, 1.0487818717956543, 1.0615917444229126, 1.0207312107086182, 0.9562033414840698, 0.9539878368377686, 0.9750841856002808, 0.9642249345779419, 0.9388570189476013, 0.9604141116142273, 0.9208709001541138, 0.9217938780784607, 0.9217938780784607]}\n",
      "model: facebook/detr-resnet-50, performte mit folgenden Scores:\n",
      "{'evaluation_results': {'eval_loss': 2.703200578689575, 'eval_runtime': 6.6684, 'eval_samples_per_second': 17.995, 'eval_steps_per_second': 2.249, 'epoch': 30.0}, 'train_losses': [4.6746, 4.3132, 3.4278, 2.8593, 2.5792, 2.596, 2.5429, 2.4819, 2.3475, 2.2264, 2.1984, 2.5366, 2.4032, 2.3265, 2.3399, 2.1198, 2.1625, 2.1945, 2.2759, 2.2185, 2.1443, 2.1945, 2.019, 1.982, 1.9171, 2.1557, 2.1643, 2.0555, 2.3052, 2.4308, 2.1464, 2.0007, 1.9337, 1.9314, 2.133, 2.0866, 1.9184, 1.8221, 1.9616, 1.9265, 1.8052, 1.7788, 1.8539, 1.7654, 1.8257, 1.822, 1.7229, 1.6468, 1.805, 1.8388, 1.6346, 1.6867, 1.7521, 1.7245, 1.6616, 1.7081, 1.6469, 1.7025, 1.646, 1.6793, 1.6547, 1.7177, 1.6524, 1.58, 1.6472, 1.6014, 1.5522, 1.6189, 1.7078, 1.6665, 1.5665, 1.4957, 1.5586, 1.5786, 1.5072, 1.5874, 1.5017, 1.4495, 1.4581, 1.5494, 1.4733, 1.5226, 1.3802, 1.5727, 1.5022, 1.4507, 1.4588, 1.4022, 1.5314, 1.4423], 'eval_losses': [3.2215707302093506, 3.2545976638793945, 2.972907781600952, 4.060675621032715, 2.834340810775757, 3.2811172008514404, 2.7086215019226074, 3.136824131011963, 3.0918350219726562, 2.8745007514953613, 2.796023368835449, 2.8119845390319824, 2.8952698707580566, 2.8209657669067383, 2.8236775398254395, 2.928908586502075, 2.9061057567596436, 2.7652242183685303, 2.875002861022949, 2.9612045288085938, 2.971139430999756, 2.862086057662964, 2.7859065532684326, 2.665994167327881, 2.66984486579895, 2.6518380641937256, 2.6940081119537354, 2.6992881298065186, 2.6927525997161865, 2.703200578689575, 2.703200578689575]}\n"
     ]
    }
   ],
   "source": [
    "for model_name, score in best_models_kugellager_dict.items():\n",
    "    print(f\"Model über alle Daten: {model_name}, performte mit folgenden Scores:\\n{score}\")\n",
    "\n",
    "for model_name, score in best_models_oberfläche_dict.items():\n",
    "    print(f\"Model über alle Daten: {model_name}, performte mit folgenden Scores:\\n{score}\")\n",
    "\n",
    "for model_name, score in best_models_kugellager_dict_halb.items():\n",
    "    print(f\"Model über hälfte der Daten: {model_name}, performte mit folgenden Scores:\\n{score}\")\n",
    "\n",
    "for model_name, score in best_models_oberfläche_dict_halb.items():\n",
    "    print(f\"Model über hälfte der Daten: {model_name}, performte mit folgenden Scores:\\n{score}\")\n",
    "\n",
    "\n",
    "with open(\"model_performance_results.txt\", \"w\") as f:\n",
    "    # Ergebnisse für best_models_kugellager_dict\n",
    "    for model_name, score in best_models_kugellager_dict.items():\n",
    "        f.write(f\"Model über alle Daten: {model_name}, performte mit folgenden Scores:\\n{score}\\n\\n\")\n",
    "\n",
    "    # Ergebnisse für best_models_oberfläche_dict\n",
    "    for model_name, score in best_models_oberfläche_dict.items():\n",
    "        f.write(f\"Model über alle Daten: {model_name}, performte mit folgenden Scores:\\n{score}\\n\\n\")\n",
    "\n",
    "    # Ergebnisse für best_models_kugellager_dict_halb\n",
    "    for model_name, score in best_models_kugellager_dict_halb.items():\n",
    "        f.write(f\"Model über hälfte der Daten: {model_name}, performte mit folgenden Scores:\\n{score}\\n\\n\")\n",
    "\n",
    "    # Ergebnisse für best_models_oberfläche_dict_halb\n",
    "    for model_name, score in best_models_oberfläche_dict_halb.items():\n",
    "        f.write(f\"Model über hälfte der Daten: {model_name}, performte mit folgenden Scores:\\n{score}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize() \n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoImageProcessor, pipeline\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# random_images = random.sample(dataset_oberfläche_test[\"image\"], 10)\n",
    "# for test_image in random_images:\n",
    "#     test = r\"C:\\Users\\anohl\\OneDrive\\Dokumente\\A_Uni_stuff\\Albstadt\\Semester 2\\Computer_vision\\Aufgaben\\trained_model\\hustvl\\yolos-tiny\\final_model\"\n",
    "#     out = pipeline(\"object-detection\", model=test, image_processor=YolosImageProcessor())(test_image, threshold=0)\n",
    "\n",
    "#     # Normalize the prediction thresholds\n",
    "#     outs = [o[\"score\"] for o in out]\n",
    "#     filtered_out = []\n",
    "#     threshold = 0.9\n",
    "#     for o in out:\n",
    "#         o[\"score\"] = 1 / max(outs) * o[\"score\"]\n",
    "#         if o[\"score\"] >= threshold:\n",
    "#             filtered_out.append(o)\n",
    "#             print(filtered_out)\n",
    "\n",
    "#     def plot_box(img, results):\n",
    "#         try:\n",
    "#             image = Image.open(img)\n",
    "#         except:\n",
    "#             image = img\n",
    "#         draw = ImageDraw.Draw(image)\n",
    "#         for i, obj in enumerate(results):\n",
    "#             box = [round(obj[\"box\"][value], 2) for value in obj[\"box\"].keys()]\n",
    "#             x, y, x2, y2 = tuple(box)\n",
    "#             draw.rectangle((x, y, x2, y2), outline=\"orange\", width=2)\n",
    "#             draw.text((x, y), f\"{obj['label']} - {np.round(obj['score'], 3)}\", fill=\"orange\", stroke_width=2, stroke_fill=\"white\")\n",
    "#         image.save(f\"./{np.random.randint(10e6)}.jpg\")\n",
    "\n",
    "#     # Visualize Results\n",
    "#     plot_box(test_image, filtered_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Verwendung von yolv8m um eine Blance zwischen performance und Genauigkeit zu haben \n",
    "# model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# # Train the model\n",
    "# path_to_yolo_yaml = os.path.join(BASE_DIR, \"yaml_files\", \"yolo_dataset.yaml\")\n",
    "# train_results = model.train(\n",
    "#     data=path_to_yolo_yaml,\n",
    "#     epochs=400,\n",
    "#     imgsz=150, # Weil das die tatsächliche Größe unserer Bilder darstellt\n",
    "#     device=device,\n",
    "#     batch=16,\n",
    "#     mosaic=1.0,\n",
    "# )\n",
    "\n",
    "# # Evaluate model performance on the validation set\n",
    "# metrics = model.val()\n",
    "# print(metrics)\n",
    "\n",
    "# # Export the model to the same directory as the script\n",
    "# export_path = os.path.join(BASE_DIR, \"Models\", \"yolo_kugellager_modell.pt\")\n",
    "# model_path = model.export()\n",
    "# shutil.move(src=model_path, dst=export_path)\n",
    "# print(f\"Model exported to: {export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = model.val()\n",
    "# print(f\"Precision: {metrics['precision']}\")\n",
    "# print(f\"Recall: {metrics['recall']}\")\n",
    "# print(f\"mAP@0.5: {metrics['map50']}\")\n",
    "# print(f\"mAP@0.5:0.95: {metrics['map']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_class_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
